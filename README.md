# ğŸš€ MMCTR Challenge - Team MMCTR from xinlab ğŸ”¥

## ğŸ† Introduction

This repository contains our solution for the **WWW 2025 Multimodal CTR Prediction Challenge** (Track 2: Multimodal CTR Prediction), organized by the **WWW 2025 EReL@MIR workshop**. The challenge focuses on developing effective multimodal representation learning and fusion methods for CTR prediction in recommendation systems.

Our solution is based on the baseline provided by the challenge organizers, with modifications and improvements in model tuning. We aim to enhance the recommendation accuracy by optimizing a new feature embedding mechanism and an  auxiliary loss.

ğŸ“Œ For details about the challenge, please visit:
-  [Challenge website](https://erel-mir.github.io/challenge/mmctr-track2/)
-  [Competition platform](https://www.codabench.org/competitions/5372/)
-  [Baseline repository](https://github.com/reczoo/WWW2025_MMCTR_Challenge)

---

## ğŸ“‚ 1. Data Preparation

 **Download the dataset** from the official source:
   - [ğŸ”— MicroLens 1M MMCTR Dataset](https://recsys.westlake.edu.cn/MicroLens_1M_MMCTR)

 **Unzip the dataset** into the `data/` directory:

```bash
cd ~/MM-CTR-MMCTRers/data/
find -L .
```

ğŸ“ **Expected data structure:**
```
./MicroLens_1M_x1/
â”œâ”€â”€ train.parquet
â”œâ”€â”€ valid.parquet
â”œâ”€â”€ test.parquet
â”œâ”€â”€ item_info.parquet
item_feature.parquet   
item_emb.parquet      
item_seq.parquet      
item_images.rar      
```

---

## ğŸ› ï¸ 2. Environment Setup

We use the same environment setup as the baseline:

```bash
conda create -n fuxictr python==3.9
pip install -r requirements.txt
source activate fuxictr
```

âœ… **Required dependencies:**
- ğŸŸ¢ torch==1.13.1+cu117
- ğŸŸ¢ fuxictr==2.3.7

ğŸ“Œ **For full setup details**, please refer to the [baseline repository](https://github.com/reczoo/WWW2025_MMCTR_Challenge).

---

## ğŸš€ 3. How to Run

After setting up the environment and downloading the dataset, simply run:

```bash
chmod +x run.sh
bash run.sh
```

 **The `run.sh` script will handle:**
1ï¸âƒ£ config set(if not ) ğŸ—ï¸
2ï¸âƒ£ Model training ğŸ¯
3ï¸âƒ£ Prediction on the test set ğŸ”
4ï¸âƒ£ Generating the final submission file ğŸ“„

**you can also modify our model and parameters as you want it by changing  ./config/DIN_attn_emb_v3**

---

## ğŸ’¬ 4. Discussion

**For any questions or discussions related to our implementation, feel free to contact us via email.**

 **Contact:** [scut201930033162@gmail.com]

---
## ğŸ“Œ TODOï¼š
    - detailed illustration of proposed algorithm
---

This document serves as the official README for our MMCTR challenge submission. Thank you! 

ğŸ”¥ If you find this work helpful , Please cite the officer paper:

+ Jieming Zhu, Jinyang Liu, Shuai Yang, Qi Zhang, Xiuqiang He. [Open Benchmarking for Click-Through Rate Prediction](https://arxiv.org/abs/2009.05794). *The 30th ACM International Conference on Information and Knowledge Management (CIKM)*, 2021.
